{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetGestes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14VbjGM3DdSB"
      },
      "source": [
        "# **Traduction de gestes de la main en emoji**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1By-TWaiq2X"
      },
      "source": [
        "# import\n",
        "\n",
        "# TORCH\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "\n",
        "# SKLEARN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# OTHER\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import pylab"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-z9w3fAi4Nx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8PKVMuZt-GG"
      },
      "source": [
        "## **Chargement des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyIzSHt0DDFz"
      },
      "source": [
        "data = np.genfromtxt('/content/drive/My Drive/DATA2020/sign_mnist_train.csv',delimiter=',')\n",
        "data = data[1:,:]\n",
        "labels = data[:,0]\n",
        "data = data[1:,1:]\n",
        "\n",
        "ind = np.argwhere((labels == 5)).reshape(-1)\n",
        "ind2 = np.argwhere((labels == 21)).reshape(-1)\n",
        "indices = np.concatenate((ind, ind2))\n",
        "data = data[indices]\n",
        "labels = labels[indices]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9eTJG7i2Hq0"
      },
      "source": [
        "data2 = np.genfromtxt('/content/drive/My Drive/DATA2020/sign_mnist_test.csv',delimiter=',')\n",
        "data2 = data2[1:,:]\n",
        "labels2 = data2[:,0]\n",
        "data2 = data2[1:,1:]\n",
        "\n",
        "ind = np.argwhere((labels2 == 5)).reshape(-1)\n",
        "ind2 = np.argwhere((labels2 == 21)).reshape(-1)\n",
        "indices = np.concatenate((ind, ind2))\n",
        "data2 = data2[indices]\n",
        "labels2 = labels2[indices]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-FYPYOJ3mwp"
      },
      "source": [
        "data = np.concatenate((data, data2))\n",
        "labels = np.concatenate((labels, labels2))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROEcKXcwfHry",
        "outputId": "bd08ab84-7bf3-43b2-f986-0613128e0bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train = data[0:2500]\n",
        "y_train = labels[0:2500]\n",
        "x_test = data[2500:]\n",
        "y_test = data[2500:]\n",
        "print(\"Data Train Shape :: \",x_train.shape)\n",
        "print(\"Data Test Shape :: \",x_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Train Shape ::  (2500, 784)\n",
            "Data Test Shape ::  (379, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtChsh0suKyY"
      },
      "source": [
        "## **CNN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQjWzX5CnwCc"
      },
      "source": [
        "class CNNGest(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNGest, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.fc1 = nn.Linear(16*7*7, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def accuracy(yhat, y):\n",
        "    return accuracy_score(y, yhat)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbwZNdjMuxWi"
      },
      "source": [
        "## **Entraînement du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmQevgYcoE2n"
      },
      "source": [
        "\n",
        "# Rechargement des données \n",
        "\n",
        "x_train = data[0:2500]\n",
        "y_train = labels[0:2500]\n",
        "x_test = data[2500:]\n",
        "y_test = data[2500:]\n",
        "\n",
        "y_train[y_train==5] = 0\n",
        "y_train[y_train==21] = 1\n",
        "y_test[y_test==5] = 0\n",
        "y_test[y_test==21] = 1\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "print(y_train)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    NB_EPOCHS = 1000 # nombre d'itération \n",
        "    BATCH_SIZE = 64\n",
        "    eps = 0.05\n",
        "    NORMA = True # normalisation\n",
        "\n",
        "    # --- TRAITEMENT DES DONNEES --- #\n",
        "\n",
        "    ## SPLIT TRAIN TEST ##\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x_train, y_train , test_size=0.2, random_state=42)\n",
        "    X_train, X_test, y_train, y_test = torch.tensor(X_train), torch.tensor(X_test), torch.tensor(y_train), torch.tensor(y_test)\n",
        "\n",
        "    # --- Normalisation des données --- #\n",
        "\n",
        "    if NORMA : \n",
        "        scaler = StandardScaler()\n",
        "        X_train = torch.tensor(scaler.fit_transform(X_train))\n",
        "        X_test = torch.tensor(scaler.fit_transform(X_test))\n",
        "\n",
        "    input_d = X_train.shape[1]\n",
        "\n",
        "    # --- CREATION DES BATCHS --- #\n",
        "\n",
        "    NB_BATCH = int(len(X_train)/BATCH_SIZE)\n",
        "\n",
        "    batch_x = list(np.split(X_train[:NB_BATCH*BATCH_SIZE], NB_BATCH))\n",
        "    batch_x.append(X_train[(NB_BATCH*BATCH_SIZE)-1:])\n",
        "    batch_y = list(np.split(y_train[:NB_BATCH*BATCH_SIZE], NB_BATCH))\n",
        "    batch_y.append(y_train[(NB_BATCH*BATCH_SIZE)-1:])\n",
        "\n",
        "    ### --- MODELs --- ###\n",
        "\n",
        "    model = CNNGest()\n",
        "\n",
        "    # --- OPTIMISEUR --- #\n",
        "\n",
        "    optim = torch.optim.SGD(params=model.parameters(),lr=eps) \n",
        "\n",
        "    optim.zero_grad()\n",
        "\n",
        "    # --- LOSS --- #\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    tabErr = []\n",
        "    tabInd = []\n",
        "    tabErr_test = []\n",
        "    acc_train = []\n",
        "    acc_test = []\n",
        "    for epoch in range(NB_EPOCHS):\n",
        "        for ind in range(NB_BATCH) : \n",
        "            x = batch_x[ind].float().view(BATCH_SIZE,1,28,28)\n",
        "            y = batch_y[ind]\n",
        "            yhat = model(x.float())\n",
        "            loss = criterion(yhat,y.long())\n",
        "\n",
        "            yhat.retain_grad()\n",
        "            loss.retain_grad()\n",
        "\n",
        "            loss.backward()\n",
        "            \n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "        \n",
        "        print(\"--- Epoch --- \"+str(epoch))\n",
        "        print(\"Loss train (Dernier batch) :: \", loss.item())\n",
        "        print(\"Accuracy train (Dernier batch) :: \", accuracy(torch.argmax(yhat, dim=1), y.long())) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyoIIxXsu2bQ"
      },
      "source": [
        "## **Sauvegarde du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FC_84aCDVXc"
      },
      "source": [
        "PATH = \"/content/drive/My Drive/DATA2020/modelGeste.pt\"\n",
        "torch.save(model, PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}